{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T03:39:41.437742Z",
     "start_time": "2019-05-14T03:39:41.415858Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T03:46:30.746270Z",
     "start_time": "2019-05-14T03:46:30.711803Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.gene_prediction.gene_prediction import read_data\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T03:40:53.703438Z",
     "start_time": "2019-05-14T03:40:37.812292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "All files loaded (15 s). Preprocessing...\n",
      "Train / test data has 15485 / 3871 genes.\n",
      "x_train shape is (15485, 500)\n",
      "y_train shape is (15485,)\n",
      "x_test shape is (3871, 500)\n",
      "Data preprocessing done...\n",
      "Next steps FOR YOU:\n",
      "------------------------------\n",
      "1. Define a classifier using sklearn\n",
      "2. Assess its accuracy using cross-validation (optional)\n",
      "3. Fine tune the parameters and return to 2 until happy (optional)\n",
      "4. Create submission file. Should be similar to y_train.csv.\n",
      "5. Submit at kaggle.com and sit back.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T04:10:58.168035Z",
     "start_time": "2019-05-14T04:10:57.961968Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_split, x_val_split, y_train_split, y_val_split = sklearn.model_selection.train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    stratify=y_train,\n",
    "    random_state=1238,\n",
    "    test_size = 0.33\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T12:28:31.874705Z",
     "start_time": "2019-05-14T12:28:31.837283Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T13:05:51.939956Z",
     "start_time": "2019-05-14T13:04:44.040454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maycownmiranda/anaconda3/envs/pattern_rec_ime_usp/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LR',\n",
       "                              LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=10000,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42, solver='warn',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('GB',\n",
       "                              GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                         init=None,\n",
       "                                                         learn...\n",
       "                                            beta_2=0.999, early_stopping=True,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(100,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_iter=500, momentum=0.9,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=42,\n",
       "                                            shuffle=True, solver='adam',\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=False, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression(max_iter=10000, random_state=42, class_weight='balanced')\n",
    "gb = GradientBoostingClassifier(random_state=42, max_depth=4, n_estimators=100)\n",
    "la = Lasso(normalize=True, max_iter=5000, random_state=42)\n",
    "mlp = MLPClassifier(random_state=42, early_stopping=True, max_iter=500)\n",
    "lsvc = LinearSVC(class_weight='balanced', random_state=42, max_iter=5000)\n",
    "svc = SVC(random_state=42, probability=True, class_weight='balanced')\n",
    "voting_clf = VotingClassifier(\n",
    "    [\n",
    "        ('LR', lr1),\n",
    "        ('GB', gb),\n",
    "        ('MLP', mlp),\n",
    "    ],\n",
    "    voting='soft')\n",
    "voting_clf.fit(x_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T13:05:52.665964Z",
     "start_time": "2019-05-14T13:05:51.945954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (Train) : 0.95654457563053\n",
      "AUC (Val): 0.9114623401362211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89      5177\n",
      "         1.0       0.90      0.88      0.89      5197\n",
      "\n",
      "    accuracy                           0.89     10374\n",
      "   macro avg       0.89      0.89      0.89     10374\n",
      "weighted avg       0.89      0.89      0.89     10374\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.84      0.85      2551\n",
      "         1.0       0.85      0.85      0.85      2560\n",
      "\n",
      "    accuracy                           0.85      5111\n",
      "   macro avg       0.85      0.85      0.85      5111\n",
      "weighted avg       0.85      0.85      0.85      5111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_class_train_split = voting_clf.predict(x_train_split)\n",
    "y_hat_class_val_split = voting_clf.predict(x_val_split)\n",
    "\n",
    "y_hat_proba_train_split = voting_clf.predict_proba(x_train_split)\n",
    "y_hat_proba_val_split = voting_clf.predict_proba(x_val_split)\n",
    "\n",
    "print(\"AUC (Train) : {}\".format(sklearn.metrics.roc_auc_score(y_train_split, y_hat_proba_train_split[:,1])))\n",
    "print(\"AUC (Val): {}\".format(sklearn.metrics.roc_auc_score(y_val_split, y_hat_proba_val_split[:,1])))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_train_split, y_hat_class_train_split))\n",
    "print(sklearn.metrics.classification_report(y_val_split, y_hat_class_val_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pattern Recognition)",
   "language": "python",
   "name": "pattern_rec_ime_usp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
